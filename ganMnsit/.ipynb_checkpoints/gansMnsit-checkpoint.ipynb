{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2756448-1140-4c69-9eea-f768ddad0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input,Dense,Reshape,Flatten,BatchNormalization,LeakyReLU\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8a5377-e1f9-438a-8b26-885e08e41f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining image dimensions\n",
    "\n",
    "imgRows = 28\n",
    "imgCols = 28\n",
    "channels = 1\n",
    "imgShape = (imgRows,imgCols,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b276af3-3e85-4432-921a-85eedb0a2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "\n",
    "    \"\"\"\n",
    "        Creates a generator model for a Generative Adversaial Network (GAN).\n",
    "\n",
    "        The generator takes a noise vector as input and transforms it into realistic looking image through a series of fully connected layers,Leaky Relu \n",
    "        activation , batch normalizations and reshaping. The final output is scaled tot the range [-1,1] using the 'tanh' activation function,\n",
    "        making it suitable for image generation tasks.\n",
    "    \n",
    "        return:\n",
    "            keras.Model : A keras model that maps noise vectors to generated images.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #Define the shape of the noise vector ; this will serve as the input to the generastor \n",
    "    # typically used in GANS, the noise vector allows the model to generate diverse outputs\n",
    "    noise_shape = (100,)\n",
    "\n",
    "    # Initilize a sequential model , which is a linear stack of layers\n",
    "    model = Sequential()\n",
    "\n",
    "    #Add a dense layer with 256 neurons, this layer acts as the first fully connected layer, transforming the \n",
    "    #input noise vector into a higher dimensional feature space.\n",
    "    #the input_shape defines the expected input noise shape dimensions \n",
    "    model.add(Dense(256,input_shape = noise_shape))\n",
    "    \n",
    "    # Add a LekyRelu activation function with a small negative slope defined by 'alpha'\n",
    "    # LeakyRelu is a variant of the standard Relu (Rectified linear unit) actibvtion function\n",
    "    # While standard RELU sets the value to 0 for all the negative inputs , this allows a small, non zero gradient for negative inputs\n",
    "    # This helps mitigate the \"dying RELU\" problem, where neurons become inactive and stop learning due to 0 gradient\n",
    "    # the alpha parameter defines the slope of the activatioin function for negative inputs. A smaller alpha means means less contibution from negative values \n",
    "    # large alpha means it allows more contribution from neagtive values.\n",
    "    # this activation helps prevent the 'dying relu' problem by allowing small gradient for negative inputs\n",
    "    model.add(LeakyRelu(alpha = 0.2))\n",
    "\n",
    "    # Add batch normalization layer to stablize and accelarate training by normalizing the activations of the previous layer.\n",
    "    # The momentum parameter controls how much of the past running statics to use.\n",
    "    # This layer also prevents internal covariate shift and improves the models generalization ability\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    # Add a Dense layer with 512 neurons to further expand the feature space.\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakuRelu(alpha = 0.2))\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    # Add another Dense layer with 1024 neurons for further expansion.\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyRelu(alpha = 0.2))\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    # Add the output Dense Layer to produce the final generated image.\n",
    "    # np.prod(image shape) caluclates the total number of pixels (flattned shape) of the output image.\n",
    "    # the activation function 'tanh' ensures that the output values are scaled bwteen -1 and 1 which is common for image generation tasks \n",
    "    model.add(Dense(np.prod(imgShape),activation = 'tanh'))\n",
    "\n",
    "    # Reshape the output to match the desired image dimensions(img Shape).\n",
    "    model.add(Reshape(imgShape))\n",
    "\n",
    "    #print model summary of the model architecture.\n",
    "    model.summary()\n",
    "\n",
    "    # define the input to the generastor which is the noise vector\n",
    "    noise = Input(shape = noise_shape)\n",
    "\n",
    "    # pass the noise vector through the model to generate image \n",
    "    img = model(noise)\n",
    "\n",
    "    # return the generator model which maps noise vector to generated images\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabb137f-8f7f-4682-8a14-5dbebc67b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "\n",
    "    model = Sequntial()\n",
    "    model.add(Flatten(inputShape = imgShape))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyRelu(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyRelu(alpha=0.2))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    model.summary()\n",
    "    img = Input(shape = imgShape)\n",
    "    validity = model(img)\n",
    "    return Model(img,validity)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a81f5b95-eab8-4288-baca-7626b10b4f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    " (X_train, _), (_, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "148fc5ed-be2d-49b6-8f35-2d95cad1e318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70857031-e3fe-4ef4-9aad-0fdedc0e7000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
