{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2756448-1140-4c69-9eea-f768ddad0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,Reshape,Flatten,BatchNormalization,LeakyReLU\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f6010b-0a93-4d14-a2b8-ab70c0750fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining image dimensions\n",
    "\n",
    "imgRows = 28\n",
    "imgCols = 28\n",
    "channels = 1\n",
    "imgShape = (imgRows,imgCols,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b276af3-3e85-4432-921a-85eedb0a2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "\n",
    "    \"\"\"\n",
    "        Creates a generator model for a Generative Adversaial Network (GAN).\n",
    "\n",
    "        The generator takes a noise vector as input and transforms it into realistic looking image through a series of fully connected layers,Leaky Relu \n",
    "        activation , batch normalizations and reshaping. The final output is scaled tot the range [-1,1] using the 'tanh' activation function,\n",
    "        making it suitable for image generation tasks.\n",
    "    \n",
    "        return:\n",
    "            keras.Model : A keras model that maps noise vectors to generated images.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #Define the shape of the noise vector ; this will serve as the input to the generastor \n",
    "    # typically used in GANS, the noise vector allows the model to generate diverse outputs\n",
    "    noise_shape = (100,)\n",
    "\n",
    "    # Initilize a sequential model , which is a linear stack of layers\n",
    "    model = Sequential()\n",
    "\n",
    "    #Add a dense layer with 256 neurons, this layer acts as the first fully connected layer, transforming the \n",
    "    #input noise vector into a higher dimensional feature space.\n",
    "    #the input_shape defines the expected input noise shape dimensions \n",
    "    model.add(Dense(256,input_shape = noise_shape))\n",
    "    \n",
    "    # Add a LekyRelu activation function with a small negative slope defined by 'alpha'\n",
    "    # LeakyRelu is a variant of the standard Relu (Rectified linear unit) actibvtion function\n",
    "    # While standard RELU sets the value to 0 for all the negative inputs , this allows a small, non zero gradient for negative inputs\n",
    "    # This helps mitigate the \"dying RELU\" problem, where neurons become inactive and stop learning due to 0 gradient\n",
    "    # the alpha parameter defines the slope of the activatioin function for negative inputs. A smaller alpha means means less contibution from negative values \n",
    "    # large alpha means it allows more contribution from neagtive values.\n",
    "    # this activation helps prevent the 'dying relu' problem by allowing small gradient for negative inputs\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "\n",
    "    # Add batch normalization layer to stablize and accelarate training by normalizing the activations of the previous layer.\n",
    "    # The momentum parameter controls how much of the past running statics to use.\n",
    "    # This layer also prevents internal covariate shift and improves the models generalization ability\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    # Add a Dense layer with 512 neurons to further expand the feature space.\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    # Add another Dense layer with 1024 neurons for further expansion.\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    # Add the output Dense Layer to produce the final generated image.\n",
    "    # np.prod(image shape) caluclates the total number of pixels (flattned shape) of the output image.\n",
    "    # the activation function 'tanh' ensures that the output values are scaled bwteen -1 and 1 which is common for image generation tasks \n",
    "    model.add(Dense(np.prod(imgShape),activation = 'tanh'))\n",
    "\n",
    "    # Reshape the output to match the desired image dimensions(img Shape).\n",
    "    model.add(Reshape(imgShape))\n",
    "\n",
    "    #print model summary of the model architecture.\n",
    "    #model.summary()\n",
    "\n",
    "    # define the input to the generastor which is the noise vector\n",
    "    noise = Input(shape = noise_shape)\n",
    "\n",
    "    # pass the noise vector through the model to generate image \n",
    "    img = model(noise)\n",
    "\n",
    "    # return the generator model which maps noise vector to generated images\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabb137f-8f7f-4682-8a14-5dbebc67b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    \"\"\"\n",
    "    Builds a desciminator model for Generative adversial network (GAN)\n",
    "\n",
    "    The descriminator acts as a binary classifier that distuingishes between real and fake images.\n",
    "    It takes an image as input ,flatten it into vector, and processes it through series of fully connected layers with leakyRelu activations. \n",
    "    The final layer uses sigmoid activation function output the porbality value representing the validity of the input image.\n",
    "\n",
    "    Returns:\n",
    "    Keras.Model : A keras model that maps an input image to validity score(0  to 1)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # initilize a sequential model for descriminators\n",
    "    model = Sequential()\n",
    "\n",
    "    # Flatten the input image from its original shape in 1D vector\n",
    "    # this prepares the image for fully connected layers\n",
    "    model.add(Flatten(input_shape = imgShape))\n",
    "\n",
    "    #Add a dense layer with 512 neurons to process the flatten layer\n",
    "    # this layer helps in learning higher-level features from input\n",
    "    model.add(Dense(512))\n",
    "\n",
    "    # add leaky relu activation function to introduce non-linearity.\n",
    "    #the small negative slope (alpha = 0.2) ensures small gradient for negative inputs.\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    #add another Dense Layer with 256 neurons for further feature extraction\n",
    "    model.add(Dense(256))\n",
    "\n",
    "    #add another LeakyRelu activation for non - linearity.\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # add the output Dense layer with 1 neuron and a single sigmoid activation function.\n",
    "    #Thje sigmoid function outputs probality between 0 and 1 , representing wheather the input image is real (closer to 1 ) or fake (closer to 0).\n",
    "    \n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "    # prints the model summary\n",
    "    #model.summary()\n",
    "\n",
    "    # defines the input to the descriminator, which is an image with same shape as the generator shape\n",
    "    img = Input(shape = imgShape)\n",
    "\n",
    "    #pass the input through the model to get the validity score.\n",
    "    validity = model(img)\n",
    "\n",
    "    #return the descriminator model, which maps an input to a validity score.\n",
    "    return Model(img,validity)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f5b95-eab8-4288-baca-7626b10b4f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 17:17:10.979423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43598 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:ce:00.0, compute capability: 8.6\n",
      "2025-01-05 17:17:15.778225: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "[D loss: 0.661026, acc.: 59.49%] [G loss: 0.615390]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Epoch 1000:\n",
      "[D loss: 0.607098, acc.: 67.38%] [G loss: 0.957948]\n",
      "Epoch 2000:\n",
      "[D loss: 0.639631, acc.: 63.76%] [G loss: 0.880633]\n",
      "Epoch 3000:\n",
      "[D loss: 0.666328, acc.: 59.41%] [G loss: 0.832610]\n",
      "Epoch 4000:\n",
      "[D loss: 0.675556, acc.: 56.42%] [G loss: 0.817644]\n",
      "Epoch 5000:\n",
      "[D loss: 0.682835, acc.: 55.08%] [G loss: 0.807822]\n",
      "Epoch 6000:\n",
      "[D loss: 0.679432, acc.: 55.48%] [G loss: 0.817320]\n",
      "Epoch 7000:\n",
      "[D loss: 0.689530, acc.: 52.34%] [G loss: 0.780299]\n",
      "Epoch 8000:\n",
      "[D loss: 0.692777, acc.: 50.27%] [G loss: 0.775519]\n",
      "Epoch 9000:\n",
      "[D loss: 0.692275, acc.: 51.22%] [G loss: 0.768376]\n",
      "Epoch 10000:\n",
      "[D loss: 0.683460, acc.: 53.49%] [G loss: 0.783809]\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Epoch 11000:\n",
      "[D loss: 0.690056, acc.: 51.93%] [G loss: 0.779655]\n",
      "Epoch 12000:\n",
      "[D loss: 0.683185, acc.: 54.24%] [G loss: 0.787557]\n",
      "Epoch 13000:\n",
      "[D loss: 0.673550, acc.: 57.65%] [G loss: 0.799349]\n",
      "Epoch 14000:\n",
      "[D loss: 0.663760, acc.: 60.17%] [G loss: 0.824637]\n",
      "Epoch 15000:\n",
      "[D loss: 0.670497, acc.: 58.00%] [G loss: 0.809661]\n",
      "Epoch 16000:\n",
      "[D loss: 0.663330, acc.: 59.82%] [G loss: 0.826205]\n",
      "Epoch 17000:\n",
      "[D loss: 0.656821, acc.: 61.63%] [G loss: 0.832776]\n",
      "Epoch 18000:\n",
      "[D loss: 0.661773, acc.: 58.62%] [G loss: 0.828336]\n",
      "Epoch 19000:\n",
      "[D loss: 0.650274, acc.: 62.31%] [G loss: 0.846514]\n",
      "Epoch 20000:\n",
      "[D loss: 0.653968, acc.: 60.91%] [G loss: 0.844405]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 21000:\n",
      "[D loss: 0.642115, acc.: 63.55%] [G loss: 0.864607]\n",
      "Epoch 22000:\n",
      "[D loss: 0.632742, acc.: 64.53%] [G loss: 0.884005]\n",
      "Epoch 23000:\n",
      "[D loss: 0.629874, acc.: 65.13%] [G loss: 0.889633]\n",
      "Epoch 24000:\n",
      "[D loss: 0.628093, acc.: 65.66%] [G loss: 0.907268]\n",
      "Epoch 25000:\n",
      "[D loss: 0.626697, acc.: 65.11%] [G loss: 0.909138]\n",
      "Epoch 26000:\n",
      "[D loss: 0.635929, acc.: 63.66%] [G loss: 0.899459]\n",
      "Epoch 27000:\n",
      "[D loss: 0.614307, acc.: 67.07%] [G loss: 0.940564]\n",
      "Epoch 28000:\n",
      "[D loss: 0.603615, acc.: 68.56%] [G loss: 0.982973]\n",
      "Epoch 29000:\n",
      "[D loss: 0.610241, acc.: 67.30%] [G loss: 0.946121]\n",
      "Epoch 30000:\n",
      "[D loss: 0.612025, acc.: 66.83%] [G loss: 0.957349]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 31000:\n",
      "[D loss: 0.601359, acc.: 68.13%] [G loss: 0.984163]\n",
      "Epoch 32000:\n",
      "[D loss: 0.596710, acc.: 68.72%] [G loss: 0.994832]\n",
      "Epoch 33000:\n",
      "[D loss: 0.589865, acc.: 69.36%] [G loss: 1.009046]\n",
      "Epoch 34000:\n",
      "[D loss: 0.587545, acc.: 69.24%] [G loss: 1.035916]\n",
      "Epoch 35000:\n",
      "[D loss: 0.599832, acc.: 67.73%] [G loss: 1.028360]\n",
      "Epoch 36000:\n",
      "[D loss: 0.573876, acc.: 71.04%] [G loss: 1.066612]\n",
      "Epoch 37000:\n",
      "[D loss: 0.565359, acc.: 71.69%] [G loss: 1.080096]\n",
      "Epoch 38000:\n",
      "[D loss: 0.579674, acc.: 69.81%] [G loss: 1.053960]\n",
      "Epoch 39000:\n",
      "[D loss: 0.571199, acc.: 70.72%] [G loss: 1.085096]\n",
      "Epoch 40000:\n",
      "[D loss: 0.558316, acc.: 72.41%] [G loss: 1.116690]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 41000:\n",
      "[D loss: 0.554207, acc.: 71.61%] [G loss: 1.124055]\n",
      "Epoch 42000:\n",
      "[D loss: 0.562113, acc.: 70.65%] [G loss: 1.137353]\n",
      "Epoch 43000:\n",
      "[D loss: 0.552835, acc.: 71.72%] [G loss: 1.153261]\n",
      "Epoch 44000:\n",
      "[D loss: 0.561814, acc.: 71.35%] [G loss: 1.137678]\n",
      "Epoch 45000:\n",
      "[D loss: 0.542797, acc.: 73.34%] [G loss: 1.166196]\n",
      "Epoch 46000:\n",
      "[D loss: 0.543400, acc.: 72.93%] [G loss: 1.200874]\n",
      "Epoch 47000:\n",
      "[D loss: 0.537241, acc.: 73.43%] [G loss: 1.208475]\n",
      "Epoch 48000:\n",
      "[D loss: 0.537422, acc.: 73.90%] [G loss: 1.226683]\n",
      "Epoch 49000:\n",
      "[D loss: 0.533067, acc.: 73.95%] [G loss: 1.222925]\n",
      "Epoch 50000:\n",
      "[D loss: 0.537836, acc.: 73.71%] [G loss: 1.218813]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 51000:\n",
      "[D loss: 0.520225, acc.: 74.63%] [G loss: 1.236839]\n",
      "Epoch 52000:\n",
      "[D loss: 0.528501, acc.: 74.19%] [G loss: 1.295099]\n",
      "Epoch 53000:\n",
      "[D loss: 0.509084, acc.: 75.65%] [G loss: 1.299744]\n",
      "Epoch 54000:\n",
      "[D loss: 0.509163, acc.: 75.24%] [G loss: 1.312769]\n",
      "Epoch 55000:\n",
      "[D loss: 0.505252, acc.: 76.06%] [G loss: 1.342971]\n",
      "Epoch 56000:\n",
      "[D loss: 0.498858, acc.: 76.45%] [G loss: 1.358092]\n",
      "Epoch 57000:\n",
      "[D loss: 0.480291, acc.: 78.13%] [G loss: 1.440172]\n",
      "Epoch 58000:\n",
      "[D loss: 0.481639, acc.: 77.73%] [G loss: 1.394435]\n",
      "Epoch 59000:\n",
      "[D loss: 0.484480, acc.: 77.41%] [G loss: 1.419446]\n",
      "Epoch 60000:\n",
      "[D loss: 0.500075, acc.: 76.14%] [G loss: 1.345570]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 61000:\n",
      "[D loss: 0.478749, acc.: 77.99%] [G loss: 1.409446]\n",
      "Epoch 62000:\n",
      "[D loss: 0.499049, acc.: 76.29%] [G loss: 1.428540]\n",
      "Epoch 63000:\n",
      "[D loss: 0.484993, acc.: 77.22%] [G loss: 1.458344]\n",
      "Epoch 64000:\n",
      "[D loss: 0.470231, acc.: 78.35%] [G loss: 1.463635]\n",
      "Epoch 65000:\n",
      "[D loss: 0.467857, acc.: 78.10%] [G loss: 1.478857]\n",
      "Epoch 67000:\n",
      "[D loss: 0.457714, acc.: 78.97%] [G loss: 1.506329]\n",
      "Epoch 68000:\n",
      "[D loss: 0.462642, acc.: 78.76%] [G loss: 1.551821]\n",
      "Epoch 69000:\n",
      "[D loss: 0.467647, acc.: 79.00%] [G loss: 1.531855]\n",
      "Epoch 70000:\n",
      "[D loss: 0.476041, acc.: 78.01%] [G loss: 1.520529]\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'images/' folder exists\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# Train Function\n",
    "def train(epochs, batchSize=128, saveInterval=50):\n",
    "    # Load the MNIST dataset\n",
    "    ds_train, ds_info = tfds.load(\n",
    "        'mnist', \n",
    "        split='train',  # Load the training data split\n",
    "        shuffle_files=True, # Shuffle the files to improve training\n",
    "        as_supervised=True, # load the data as (image, label) pairs\n",
    "        with_info=True #also load the dataset metadat like (e.g: , image dimansions)\n",
    "    )\n",
    "    \n",
    "    #Extract only images and ignore labels\n",
    "    ds_train_images = ds_train.map(lambda image, label: image)\n",
    "\n",
    "    def normalize_img(image):\n",
    "        image = tf.cast(image, tf.float32) / 127.5 - 1.0 # normalize from ([0,255] to [-1 to 1])\n",
    "        image = tf.expand_dims(image, axis=-1) # add an extra channel axis(for gray scale)raining\n",
    "        return image\n",
    "\n",
    "    ds_train_images = ds_train_images.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train_images = ds_train_images.cache() # cache the dataset to speed up subsequent epochs\n",
    "    ds_train_images = ds_train_images.batch(batchSize) # set the batch size\n",
    "    ds_train_images = ds_train_images.prefetch(tf.data.AUTOTUNE) # prefectc the dat fro faster loading during \n",
    "\n",
    "    halfBatch = int(batchSize / 2) # Half batch size for training the discriminator\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        \n",
    "        for real_imgs in ds_train_images:\n",
    "            # Train Discriminator\n",
    "            idx = np.random.randint(0, real_imgs.shape[0], halfBatch) # select random half batch for real images\n",
    "            real_half_batch = tf.gather(real_imgs, idx) # gather the real half batch\n",
    "    \n",
    "            noise = np.random.normal(0, 1, (halfBatch, 100)) # generate random noise for fake images\n",
    "            gen_imgs = generator_model(noise, training=True) # generate fake images from noise\n",
    "    \n",
    "            # remove the last dimensions if necessary        \n",
    "            real_half_batch = tf.squeeze(real_half_batch, axis=-1)\n",
    "\n",
    "            # train the discriminator on real and fake images\n",
    "            d_loss_real = discriminator_model.train_on_batch(real_half_batch, tf.ones((halfBatch, 1))) # train on real images\n",
    "            d_loss_fake = discriminator_model.train_on_batch(gen_imgs, tf.zeros((halfBatch, 1))) # train on fake images\n",
    "\n",
    "            # take average loss rfom real and fake images\n",
    "            d_loss = 0.5 * tf.add(d_loss_real, d_loss_fake).numpy()  # Convert to NumPy for easier inspection \n",
    "\n",
    "            # withing the same loop train the geenrators by setting the input noise and ultimately\n",
    "            # training the generator to have the discriminator label its  samples as valid by specifying the gradient loss\n",
    "            \n",
    "            \n",
    "            # Train Generator\n",
    "\n",
    "            #\n",
    "            noise = np.random.normal(0, 1, (batchSize, 100)) # generate new noises for training the generator\n",
    "            valid_y = np.ones((batchSize, 1)) # labels indicating the geenrated images are \"real\"\n",
    "            g_loss = combined.train_on_batch(noise, valid_y) # train the generator with labels of real images\n",
    "\n",
    "            # print losses at specified intervals\n",
    "            if epoch % 1000 == 0: \n",
    "                print(f\"Epoch {epoch}:\")\n",
    "                print(\"[D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "        # save generated images at specified intervals\n",
    "        if epoch % saveInterval == 0:\n",
    "            save_imgs(epoch)\n",
    "\n",
    "\n",
    "# Save Images\n",
    "def save_imgs(epoch):\n",
    "    r, c = 5, 5 # set the grid size\n",
    "    noise = np.random.normal(0, 1, (r * c, 100)) # generate the noise for the grid of imagges\n",
    "    gen_imgs = generator_model.predict(noise) # generate images for the noise input\n",
    "\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5 # Rescale the generated images from [-1,1] to [0,1]\n",
    "\n",
    "    fig, axs = plt.subplots(r, c) # create a grid for platting images\n",
    "    cnt = 0 # counter for images\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray') # dispaly each generated images in grayscale \n",
    "            axs[i, j].axis('off') # hide axis for clean image output\n",
    "            cnt += 1\n",
    "    fig.savefig(f\"images/mnist_{epoch}.png\") # save the image grid to file \n",
    "    plt.close() # close the figure to avoid memory issues\n",
    "\n",
    "# Optimizer\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "\n",
    "optimizer = legacy.Adam(learning_rate=0.0002, beta_1=0.5) # define the adam optimizer\n",
    "\n",
    "# Discriminator\n",
    "\n",
    "\n",
    "# Build and compile the discriminator first. \n",
    "#Generator will be trained as part of the combined model, later. \n",
    "#pick the loss function and the type of metric to keep track.                 \n",
    "#Binary cross entropy as we are doing prediction and it is a better\n",
    "#loss function compared to MSE or other. \n",
    "\n",
    "\n",
    "discriminator_model = discriminator() # initilize the discriminator model\n",
    "discriminator_model.compile(\n",
    "    loss=\"binary_crossentropy\",  # use binary cross entropy for binary classification\n",
    "    optimizer=optimizer, # use adam optimizer\n",
    "    metrics=['accuracy'] # track accuracy\n",
    ")\n",
    "\n",
    "# Generator\n",
    "generator_model = generator() # Initilize the generator model\n",
    "generator_model.compile(loss=\"binary_crossentropy\", # use the binary cross entropy loss for the geenrator\n",
    "                        optimizer=optimizer) # \n",
    "\n",
    "# Combined Model\n",
    "z = Input(shape=(100,)) # inpout noise vector for the generator \n",
    "img = generator_model(z) # generate an image from the noise  vector\n",
    "discriminator_model.trainable = False # freeze the discriminator during generatoe training\n",
    "valid = discriminator_model(img) # the velidiity of the geenrated image (real or fake)\n",
    "combined = Model(z, valid) # combine mode : generaotr + discriminator\n",
    "combined.compile(loss=\"binary_crossentropy\", optimizer=optimizer) # compile the combined model with loss and optimizer\n",
    "\n",
    "# Train GAN\n",
    "train(epochs=100000, batchSize=60000, saveInterval=10000) # start thr training process with large abtch size and save every 10k epochs\n",
    "\n",
    "# Save Generator Model\n",
    "generator_model.save('generator_model') #save the trained generator model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186519d5-d112-4229-9761-9837aab67fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
